{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP using PySpark\n",
    "\n",
    "1. spark sql로 데이터를 로드\n",
    "2. document 열 생성\n",
    "3. Spark NLP로 처리\n",
    "4. 관심있는 애너테이션을 Spark SQL 데이터 타입으로 변환\n",
    "5. 추가적이 MLlib stage를 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparkSession 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Spark\\\\spark-3.1.2-bin-hadoop3.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "packages = ','.join([\n",
    "    \"com.johnsnowlabs.nlp:spark-nlp_2.12:3.3.2\"\n",
    "])\n",
    "\n",
    "spark_conf = SparkConf()\\\n",
    "    .setAppName('Spark NLP Pipeline')\\\n",
    "    .setAppName('master[*]')\\\n",
    "    .set('spark.jars.packages', packages)\n",
    "spark = SparkSession.builder\\\n",
    "    .config(conf=spark_conf)\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load (with Spark SQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "text_path = os.path.join('../Data', '3구간', '1시기', '1시기_ST')\n",
    "\n",
    "# 파일 경로-텍스트 와 같은 쌍을 포함하는 RDD\n",
    "texts = spark.sparkContext.wholeTextFiles(text_path)\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('path', StringType()),\n",
    "    StructField('text', StringType()),\n",
    "])\n",
    "\n",
    "texts = spark.createDataFrame(texts, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>America's Germany\\r\\n\\r\\nAmid ruins the occupa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>ILYA EHRENBURG'S AMERICA\\r\\n\\r\\nTranslations o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>NO REST FOR THE\\r\\nWEARY RUSSIANS\\r\\n\\r\\nJOHN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>Our Ally, Russia\\r\\n\\r\\nON THURSDAY, September...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>Our record in Japan \\r\\n\\r\\nMaxwell Stewart \\r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  \\\n",
       "0  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "1  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "2  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "3  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "4  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "\n",
       "                                                text  \n",
       "0  America's Germany\\r\\n\\r\\nAmid ruins the occupa...  \n",
       "1  ILYA EHRENBURG'S AMERICA\\r\\n\\r\\nTranslations o...  \n",
       "2  NO REST FOR THE\\r\\nWEARY RUSSIANS\\r\\n\\r\\nJOHN ...  \n",
       "3  Our Ally, Russia\\r\\n\\r\\nON THURSDAY, September...  \n",
       "4  Our record in Japan \\r\\n\\r\\nMaxwell Stewart \\r...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documetn Assembler\n",
    "\n",
    "텍스트를 문서 객체로 변환\n",
    "\n",
    "- inputCol : 도큐먼트의 텍스트를 포함하는 열\n",
    "- outputCol : 새로 생성된 도큐먼트를 포함하는 열 이름\n",
    "- idCol : 식별자가 포함된 열 이름 (Optional)\n",
    "- metadataCol : 도큐먼트 메타데이터를 나타내는 Map 타입의 열 이름(선택 사항)\n",
    "- trimAndClearNewLines : 개행 문자와 문자열 공백을 제거할지를 결정(Optional, default=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>America's Germany\\r\\n\\r\\nAmid ruins the occupa...</td>\n",
       "      <td>[(document, 0, 30585, America's Germany\\r\\n\\r\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>ILYA EHRENBURG'S AMERICA\\r\\n\\r\\nTranslations o...</td>\n",
       "      <td>[(document, 0, 61303, ILYA EHRENBURG'S AMERICA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>NO REST FOR THE\\r\\nWEARY RUSSIANS\\r\\n\\r\\nJOHN ...</td>\n",
       "      <td>[(document, 0, 41364, NO REST FOR THE\\r\\nWEARY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>Our Ally, Russia\\r\\n\\r\\nON THURSDAY, September...</td>\n",
       "      <td>[(document, 0, 58337, Our Ally, Russia\\r\\n\\r\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>Our record in Japan \\r\\n\\r\\nMaxwell Stewart \\r...</td>\n",
       "      <td>[(document, 0, 16662, Our record in Japan \\r\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  \\\n",
       "0  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "1  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "2  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "3  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "4  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "\n",
       "                                                text  \\\n",
       "0  America's Germany\\r\\n\\r\\nAmid ruins the occupa...   \n",
       "1  ILYA EHRENBURG'S AMERICA\\r\\n\\r\\nTranslations o...   \n",
       "2  NO REST FOR THE\\r\\nWEARY RUSSIANS\\r\\n\\r\\nJOHN ...   \n",
       "3  Our Ally, Russia\\r\\n\\r\\nON THURSDAY, September...   \n",
       "4  Our record in Japan \\r\\n\\r\\nMaxwell Stewart \\r...   \n",
       "\n",
       "                                            document  \n",
       "0  [(document, 0, 30585, America's Germany\\r\\n\\r\\...  \n",
       "1  [(document, 0, 61303, ILYA EHRENBURG'S AMERICA...  \n",
       "2  [(document, 0, 41364, NO REST FOR THE\\r\\nWEARY...  \n",
       "3  [(document, 0, 58337, Our Ally, Russia\\r\\n\\r\\n...  \n",
       "4  [(document, 0, 16662, Our record in Japan \\r\\n...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparknlp import DocumentAssembler, Finisher\n",
    "\n",
    "document_assembler = DocumentAssembler()\\\n",
    "    .setInputCol('text')\\\n",
    "    .setOutputCol('document')\\\n",
    "    .setIdCol('path')\n",
    "docs = document_assembler.transform(texts)\n",
    "\n",
    "docs.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 애너테이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SentenceDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>document</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>America's Germany\\r\\n\\r\\nAmid ruins the occupa...</td>\n",
       "      <td>[(document, 0, 30585, America's Germany\\r\\n\\r\\...</td>\n",
       "      <td>[(document, 0, 138, America's Germany\\r\\n\\r\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>ILYA EHRENBURG'S AMERICA\\r\\n\\r\\nTranslations o...</td>\n",
       "      <td>[(document, 0, 61303, ILYA EHRENBURG'S AMERICA...</td>\n",
       "      <td>[(document, 0, 255, ILYA EHRENBURG'S AMERICA\\r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>NO REST FOR THE\\r\\nWEARY RUSSIANS\\r\\n\\r\\nJOHN ...</td>\n",
       "      <td>[(document, 0, 41364, NO REST FOR THE\\r\\nWEARY...</td>\n",
       "      <td>[(document, 0, 117, NO REST FOR THE\\r\\nWEARY R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>Our Ally, Russia\\r\\n\\r\\nON THURSDAY, September...</td>\n",
       "      <td>[(document, 0, 58337, Our Ally, Russia\\r\\n\\r\\n...</td>\n",
       "      <td>[(document, 0, 202, Our Ally, Russia\\r\\n\\r\\nON...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>Our record in Japan \\r\\n\\r\\nMaxwell Stewart \\r...</td>\n",
       "      <td>[(document, 0, 16662, Our record in Japan \\r\\n...</td>\n",
       "      <td>[(document, 0, 140, Our record in Japan \\r\\n\\r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  \\\n",
       "0  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "1  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "2  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "3  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "4  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "\n",
       "                                                text  \\\n",
       "0  America's Germany\\r\\n\\r\\nAmid ruins the occupa...   \n",
       "1  ILYA EHRENBURG'S AMERICA\\r\\n\\r\\nTranslations o...   \n",
       "2  NO REST FOR THE\\r\\nWEARY RUSSIANS\\r\\n\\r\\nJOHN ...   \n",
       "3  Our Ally, Russia\\r\\n\\r\\nON THURSDAY, September...   \n",
       "4  Our record in Japan \\r\\n\\r\\nMaxwell Stewart \\r...   \n",
       "\n",
       "                                            document  \\\n",
       "0  [(document, 0, 30585, America's Germany\\r\\n\\r\\...   \n",
       "1  [(document, 0, 61303, ILYA EHRENBURG'S AMERICA...   \n",
       "2  [(document, 0, 41364, NO REST FOR THE\\r\\nWEARY...   \n",
       "3  [(document, 0, 58337, Our Ally, Russia\\r\\n\\r\\n...   \n",
       "4  [(document, 0, 16662, Our record in Japan \\r\\n...   \n",
       "\n",
       "                                           sentences  \n",
       "0  [(document, 0, 138, America's Germany\\r\\n\\r\\nA...  \n",
       "1  [(document, 0, 255, ILYA EHRENBURG'S AMERICA\\r...  \n",
       "2  [(document, 0, 117, NO REST FOR THE\\r\\nWEARY R...  \n",
       "3  [(document, 0, 202, Our Ally, Russia\\r\\n\\r\\nON...  \n",
       "4  [(document, 0, 140, Our record in Japan \\r\\n\\r...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparknlp.annotator import SentenceDetector\n",
    "\n",
    "sent_detector = SentenceDetector()\\\n",
    "    .setInputCols(['document'])\\\n",
    "    .setOutputCol('sentences')\\\n",
    "    .setUseAbbreviations(True)\n",
    "\n",
    "sentences = sent_detector.transform(docs)\n",
    "sentences.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>document</th>\n",
       "      <th>sentences</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>America's Germany\\r\\n\\r\\nAmid ruins the occupa...</td>\n",
       "      <td>[(document, 0, 30585, America's Germany\\r\\n\\r\\...</td>\n",
       "      <td>[(document, 0, 138, America's Germany\\r\\n\\r\\nA...</td>\n",
       "      <td>[(token, 0, 8, America's, {'sentence': '0'}, [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>ILYA EHRENBURG'S AMERICA\\r\\n\\r\\nTranslations o...</td>\n",
       "      <td>[(document, 0, 61303, ILYA EHRENBURG'S AMERICA...</td>\n",
       "      <td>[(document, 0, 255, ILYA EHRENBURG'S AMERICA\\r...</td>\n",
       "      <td>[(token, 0, 3, ILYA, {'sentence': '0'}, []), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>NO REST FOR THE\\r\\nWEARY RUSSIANS\\r\\n\\r\\nJOHN ...</td>\n",
       "      <td>[(document, 0, 41364, NO REST FOR THE\\r\\nWEARY...</td>\n",
       "      <td>[(document, 0, 117, NO REST FOR THE\\r\\nWEARY R...</td>\n",
       "      <td>[(token, 0, 1, NO, {'sentence': '0'}, []), (to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>Our Ally, Russia\\r\\n\\r\\nON THURSDAY, September...</td>\n",
       "      <td>[(document, 0, 58337, Our Ally, Russia\\r\\n\\r\\n...</td>\n",
       "      <td>[(document, 0, 202, Our Ally, Russia\\r\\n\\r\\nON...</td>\n",
       "      <td>[(token, 0, 2, Our, {'sentence': '0'}, []), (t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>Our record in Japan \\r\\n\\r\\nMaxwell Stewart \\r...</td>\n",
       "      <td>[(document, 0, 16662, Our record in Japan \\r\\n...</td>\n",
       "      <td>[(document, 0, 140, Our record in Japan \\r\\n\\r...</td>\n",
       "      <td>[(token, 0, 2, Our, {'sentence': '0'}, []), (t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  \\\n",
       "0  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "1  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "2  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "3  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "4  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "\n",
       "                                                text  \\\n",
       "0  America's Germany\\r\\n\\r\\nAmid ruins the occupa...   \n",
       "1  ILYA EHRENBURG'S AMERICA\\r\\n\\r\\nTranslations o...   \n",
       "2  NO REST FOR THE\\r\\nWEARY RUSSIANS\\r\\n\\r\\nJOHN ...   \n",
       "3  Our Ally, Russia\\r\\n\\r\\nON THURSDAY, September...   \n",
       "4  Our record in Japan \\r\\n\\r\\nMaxwell Stewart \\r...   \n",
       "\n",
       "                                            document  \\\n",
       "0  [(document, 0, 30585, America's Germany\\r\\n\\r\\...   \n",
       "1  [(document, 0, 61303, ILYA EHRENBURG'S AMERICA...   \n",
       "2  [(document, 0, 41364, NO REST FOR THE\\r\\nWEARY...   \n",
       "3  [(document, 0, 58337, Our Ally, Russia\\r\\n\\r\\n...   \n",
       "4  [(document, 0, 16662, Our record in Japan \\r\\n...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [(document, 0, 138, America's Germany\\r\\n\\r\\nA...   \n",
       "1  [(document, 0, 255, ILYA EHRENBURG'S AMERICA\\r...   \n",
       "2  [(document, 0, 117, NO REST FOR THE\\r\\nWEARY R...   \n",
       "3  [(document, 0, 202, Our Ally, Russia\\r\\n\\r\\nON...   \n",
       "4  [(document, 0, 140, Our record in Japan \\r\\n\\r...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [(token, 0, 8, America's, {'sentence': '0'}, [...  \n",
       "1  [(token, 0, 3, ILYA, {'sentence': '0'}, []), (...  \n",
       "2  [(token, 0, 1, NO, {'sentence': '0'}, []), (to...  \n",
       "3  [(token, 0, 2, Our, {'sentence': '0'}, []), (t...  \n",
       "4  [(token, 0, 2, Our, {'sentence': '0'}, []), (t...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparknlp.annotator import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\\\n",
    "    .setInputCols(['sentences'])\\\n",
    "    .setOutputCol('tokens')\\\n",
    "    .fit(sentences)\n",
    "\n",
    "tokens = tokenizer.transform(sentences)\n",
    "tokens.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>document</th>\n",
       "      <th>sentences</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>America's Germany\\r\\n\\r\\nAmid ruins the occupa...</td>\n",
       "      <td>[(document, 0, 30585, America's Germany\\r\\n\\r\\...</td>\n",
       "      <td>[(document, 0, 138, America's Germany\\r\\n\\r\\nA...</td>\n",
       "      <td>[(token, 0, 8, America's, {'sentence': '0'}, [...</td>\n",
       "      <td>[(token, 0, 8, America's, {'sentence': '0'}, [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>ILYA EHRENBURG'S AMERICA\\r\\n\\r\\nTranslations o...</td>\n",
       "      <td>[(document, 0, 61303, ILYA EHRENBURG'S AMERICA...</td>\n",
       "      <td>[(document, 0, 255, ILYA EHRENBURG'S AMERICA\\r...</td>\n",
       "      <td>[(token, 0, 3, ILYA, {'sentence': '0'}, []), (...</td>\n",
       "      <td>[(token, 0, 3, ILYA, {'sentence': '0'}, []), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>NO REST FOR THE\\r\\nWEARY RUSSIANS\\r\\n\\r\\nJOHN ...</td>\n",
       "      <td>[(document, 0, 41364, NO REST FOR THE\\r\\nWEARY...</td>\n",
       "      <td>[(document, 0, 117, NO REST FOR THE\\r\\nWEARY R...</td>\n",
       "      <td>[(token, 0, 1, NO, {'sentence': '0'}, []), (to...</td>\n",
       "      <td>[(token, 0, 1, NO, {'sentence': '0'}, []), (to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>Our Ally, Russia\\r\\n\\r\\nON THURSDAY, September...</td>\n",
       "      <td>[(document, 0, 58337, Our Ally, Russia\\r\\n\\r\\n...</td>\n",
       "      <td>[(document, 0, 202, Our Ally, Russia\\r\\n\\r\\nON...</td>\n",
       "      <td>[(token, 0, 2, Our, {'sentence': '0'}, []), (t...</td>\n",
       "      <td>[(token, 0, 2, Our, {'sentence': '0'}, []), (t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>Our record in Japan \\r\\n\\r\\nMaxwell Stewart \\r...</td>\n",
       "      <td>[(document, 0, 16662, Our record in Japan \\r\\n...</td>\n",
       "      <td>[(document, 0, 140, Our record in Japan \\r\\n\\r...</td>\n",
       "      <td>[(token, 0, 2, Our, {'sentence': '0'}, []), (t...</td>\n",
       "      <td>[(token, 0, 2, Our, {'sentence': '0'}, []), (t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  \\\n",
       "0  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "1  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "2  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "3  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "4  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "\n",
       "                                                text  \\\n",
       "0  America's Germany\\r\\n\\r\\nAmid ruins the occupa...   \n",
       "1  ILYA EHRENBURG'S AMERICA\\r\\n\\r\\nTranslations o...   \n",
       "2  NO REST FOR THE\\r\\nWEARY RUSSIANS\\r\\n\\r\\nJOHN ...   \n",
       "3  Our Ally, Russia\\r\\n\\r\\nON THURSDAY, September...   \n",
       "4  Our record in Japan \\r\\n\\r\\nMaxwell Stewart \\r...   \n",
       "\n",
       "                                            document  \\\n",
       "0  [(document, 0, 30585, America's Germany\\r\\n\\r\\...   \n",
       "1  [(document, 0, 61303, ILYA EHRENBURG'S AMERICA...   \n",
       "2  [(document, 0, 41364, NO REST FOR THE\\r\\nWEARY...   \n",
       "3  [(document, 0, 58337, Our Ally, Russia\\r\\n\\r\\n...   \n",
       "4  [(document, 0, 16662, Our record in Japan \\r\\n...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [(document, 0, 138, America's Germany\\r\\n\\r\\nA...   \n",
       "1  [(document, 0, 255, ILYA EHRENBURG'S AMERICA\\r...   \n",
       "2  [(document, 0, 117, NO REST FOR THE\\r\\nWEARY R...   \n",
       "3  [(document, 0, 202, Our Ally, Russia\\r\\n\\r\\nON...   \n",
       "4  [(document, 0, 140, Our record in Japan \\r\\n\\r...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [(token, 0, 8, America's, {'sentence': '0'}, [...   \n",
       "1  [(token, 0, 3, ILYA, {'sentence': '0'}, []), (...   \n",
       "2  [(token, 0, 1, NO, {'sentence': '0'}, []), (to...   \n",
       "3  [(token, 0, 2, Our, {'sentence': '0'}, []), (t...   \n",
       "4  [(token, 0, 2, Our, {'sentence': '0'}, []), (t...   \n",
       "\n",
       "                                               lemma  \n",
       "0  [(token, 0, 8, America's, {'sentence': '0'}, [...  \n",
       "1  [(token, 0, 3, ILYA, {'sentence': '0'}, []), (...  \n",
       "2  [(token, 0, 1, NO, {'sentence': '0'}, []), (to...  \n",
       "3  [(token, 0, 2, Our, {'sentence': '0'}, []), (t...  \n",
       "4  [(token, 0, 2, Our, {'sentence': '0'}, []), (t...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparknlp.annotator import Lemmatizer\n",
    "\n",
    "lemmatizer = Lemmatizer()\\\n",
    "    .setInputCols([\"tokens\"])\\\n",
    "    .setOutputCol(\"lemma\")\\\n",
    "    .setDictionary('en_lemmas.txt', '\\t', ',')\\\n",
    "    .fit(tokens)\n",
    "\n",
    "lemmas = lemmatizer.transform(tokens)\n",
    "lemmas.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pos tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_anc download started this may take some time.\n",
      "Approximate size to download 3.9 MB\n",
      "[OK!]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>document</th>\n",
       "      <th>sentences</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>America's Germany\\r\\n\\r\\nAmid ruins the occupa...</td>\n",
       "      <td>[(document, 0, 30585, America's Germany\\r\\n\\r\\...</td>\n",
       "      <td>[(document, 0, 138, America's Germany\\r\\n\\r\\nA...</td>\n",
       "      <td>[(token, 0, 8, America's, {'sentence': '0'}, [...</td>\n",
       "      <td>[(token, 0, 8, America's, {'sentence': '0'}, [...</td>\n",
       "      <td>[(pos, 0, 8, NNP, {'sentence': '0', 'word': 'A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>ILYA EHRENBURG'S AMERICA\\r\\n\\r\\nTranslations o...</td>\n",
       "      <td>[(document, 0, 61303, ILYA EHRENBURG'S AMERICA...</td>\n",
       "      <td>[(document, 0, 255, ILYA EHRENBURG'S AMERICA\\r...</td>\n",
       "      <td>[(token, 0, 3, ILYA, {'sentence': '0'}, []), (...</td>\n",
       "      <td>[(token, 0, 3, ILYA, {'sentence': '0'}, []), (...</td>\n",
       "      <td>[(pos, 0, 3, NNP, {'sentence': '0', 'word': 'I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>NO REST FOR THE\\r\\nWEARY RUSSIANS\\r\\n\\r\\nJOHN ...</td>\n",
       "      <td>[(document, 0, 41364, NO REST FOR THE\\r\\nWEARY...</td>\n",
       "      <td>[(document, 0, 117, NO REST FOR THE\\r\\nWEARY R...</td>\n",
       "      <td>[(token, 0, 1, NO, {'sentence': '0'}, []), (to...</td>\n",
       "      <td>[(token, 0, 1, NO, {'sentence': '0'}, []), (to...</td>\n",
       "      <td>[(pos, 0, 1, DT, {'sentence': '0', 'word': 'NO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>Our Ally, Russia\\r\\n\\r\\nON THURSDAY, September...</td>\n",
       "      <td>[(document, 0, 58337, Our Ally, Russia\\r\\n\\r\\n...</td>\n",
       "      <td>[(document, 0, 202, Our Ally, Russia\\r\\n\\r\\nON...</td>\n",
       "      <td>[(token, 0, 2, Our, {'sentence': '0'}, []), (t...</td>\n",
       "      <td>[(token, 0, 2, Our, {'sentence': '0'}, []), (t...</td>\n",
       "      <td>[(pos, 0, 2, PRP$, {'sentence': '0', 'word': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...</td>\n",
       "      <td>Our record in Japan \\r\\n\\r\\nMaxwell Stewart \\r...</td>\n",
       "      <td>[(document, 0, 16662, Our record in Japan \\r\\n...</td>\n",
       "      <td>[(document, 0, 140, Our record in Japan \\r\\n\\r...</td>\n",
       "      <td>[(token, 0, 2, Our, {'sentence': '0'}, []), (t...</td>\n",
       "      <td>[(token, 0, 2, Our, {'sentence': '0'}, []), (t...</td>\n",
       "      <td>[(pos, 0, 2, PRP$, {'sentence': '0', 'word': '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  \\\n",
       "0  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "1  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "2  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "3  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "4  file:/c:/Text-Mining-Project/Data/3구간/1시기/1시기_...   \n",
       "\n",
       "                                                text  \\\n",
       "0  America's Germany\\r\\n\\r\\nAmid ruins the occupa...   \n",
       "1  ILYA EHRENBURG'S AMERICA\\r\\n\\r\\nTranslations o...   \n",
       "2  NO REST FOR THE\\r\\nWEARY RUSSIANS\\r\\n\\r\\nJOHN ...   \n",
       "3  Our Ally, Russia\\r\\n\\r\\nON THURSDAY, September...   \n",
       "4  Our record in Japan \\r\\n\\r\\nMaxwell Stewart \\r...   \n",
       "\n",
       "                                            document  \\\n",
       "0  [(document, 0, 30585, America's Germany\\r\\n\\r\\...   \n",
       "1  [(document, 0, 61303, ILYA EHRENBURG'S AMERICA...   \n",
       "2  [(document, 0, 41364, NO REST FOR THE\\r\\nWEARY...   \n",
       "3  [(document, 0, 58337, Our Ally, Russia\\r\\n\\r\\n...   \n",
       "4  [(document, 0, 16662, Our record in Japan \\r\\n...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [(document, 0, 138, America's Germany\\r\\n\\r\\nA...   \n",
       "1  [(document, 0, 255, ILYA EHRENBURG'S AMERICA\\r...   \n",
       "2  [(document, 0, 117, NO REST FOR THE\\r\\nWEARY R...   \n",
       "3  [(document, 0, 202, Our Ally, Russia\\r\\n\\r\\nON...   \n",
       "4  [(document, 0, 140, Our record in Japan \\r\\n\\r...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [(token, 0, 8, America's, {'sentence': '0'}, [...   \n",
       "1  [(token, 0, 3, ILYA, {'sentence': '0'}, []), (...   \n",
       "2  [(token, 0, 1, NO, {'sentence': '0'}, []), (to...   \n",
       "3  [(token, 0, 2, Our, {'sentence': '0'}, []), (t...   \n",
       "4  [(token, 0, 2, Our, {'sentence': '0'}, []), (t...   \n",
       "\n",
       "                                               lemma  \\\n",
       "0  [(token, 0, 8, America's, {'sentence': '0'}, [...   \n",
       "1  [(token, 0, 3, ILYA, {'sentence': '0'}, []), (...   \n",
       "2  [(token, 0, 1, NO, {'sentence': '0'}, []), (to...   \n",
       "3  [(token, 0, 2, Our, {'sentence': '0'}, []), (t...   \n",
       "4  [(token, 0, 2, Our, {'sentence': '0'}, []), (t...   \n",
       "\n",
       "                                                 pos  \n",
       "0  [(pos, 0, 8, NNP, {'sentence': '0', 'word': 'A...  \n",
       "1  [(pos, 0, 3, NNP, {'sentence': '0', 'word': 'I...  \n",
       "2  [(pos, 0, 1, DT, {'sentence': '0', 'word': 'NO...  \n",
       "3  [(pos, 0, 2, PRP$, {'sentence': '0', 'word': '...  \n",
       "4  [(pos, 0, 2, PRP$, {'sentence': '0', 'word': '...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparknlp.annotator import PerceptronModel\n",
    "\n",
    "pos_tagger = PerceptronModel.pretrained()\\\n",
    "    .setInputCols([\"tokens\", \"sentences\"])\\\n",
    "    .setOutputCol(\"pos\")\n",
    "\n",
    "postags = pos_tagger.transform(lemmas)\n",
    "postags.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "33a3111211be4281f3a8c4a9b25563b8d253df502c7e31f5318895c1792a97cb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('py38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
