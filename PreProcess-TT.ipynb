{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Module Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self defined moduels\n",
    "from myModules.utils import DataLoader\n",
    "from myModules.preprocess.korean import cleaning, remove_stopword, tagging, tokenizing, to_pickle\n",
    "\n",
    "\n",
    "# General Module\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Read File\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = './Data/3구간/'\n",
    "\n",
    "PERIOD_1 = DATA_ROOT + '1시기/1시기_TT/'\n",
    "PERIOD_2 = DATA_ROOT + '2시기/2시기_TT/'\n",
    "PERIOD_3 = DATA_ROOT + '3시기/3시기_TT/'\n",
    "\n",
    "RESULT_ROOT = './processed-data/'\n",
    "\n",
    "RESULT_1 = RESULT_ROOT + '/period-1/TT/'\n",
    "RESULT_2 = RESULT_ROOT + '/period-2/TT/'\n",
    "RESULT_3 = RESULT_ROOT + '/period-3/TT/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_1 = glob.glob(PERIOD_1+'*.txt')\n",
    "files_2 = glob.glob(PERIOD_2+'*.txt')\n",
    "files_3 = glob.glob(PERIOD_3+'*.txt')\n",
    "\n",
    "texts_1 = DataLoader(files_1, mode='TT')\n",
    "texts_2 = DataLoader(files_2, mode='TT')\n",
    "texts_3 = DataLoader(files_3, mode='TT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PreProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_1 = cleaning(texts_1)\n",
    "cleaned_2 = cleaning(texts_2)\n",
    "cleaned_3 = cleaning(texts_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17493d33d4d54d76ba7b5af8945d221a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "POS tagging:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2f4e072f994684a84a7d8f45cde0a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "POS tagging:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c461b370c549f79583a115c990d733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "POS tagging:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tagged_1 = tagging(cleaned_1)\n",
    "tagged_2 = tagging(cleaned_2)\n",
    "tagged_3 = tagging(cleaned_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3. Remove Stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagList = pd.read_pickle('./processed-data/pos-table.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_tag_list = ['IC', 'JC', 'JK', 'JKC', 'JKG', 'JKI', 'JKM', 'JKO', 'JKQ', 'JKS', 'JX', 'EPH', \\\n",
    "    'EPT', 'EPP', 'EFN', 'EFQ', 'EFO', 'EFA', 'EFI', 'EFR', 'ECE', 'ECD', 'ECS', 'ETN', 'ETD',\n",
    "    'XSN', 'XSV', 'XSA', 'UN', 'OH', 'OL', 'ON', 'XPN', 'XPV', 'XR']\n",
    "\n",
    "Kor_stopwords = ''\n",
    "\n",
    "with open(\"./Data/Kor_stopwords.txt\", 'r', encoding='utf-8') as f:\n",
    "    stopword = f.read()\n",
    "    Kor_stopwords = stopword\n",
    "\n",
    "Kor_stopwords = Kor_stopwords.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21552942aec8427784b06a28007011ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Removing Stop Words:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bdc56b2aab1477ab4b750b5e60e2376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Removing Stop Words:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f782c8454c274b52863c275ff61e3f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Removing Stop Words:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wo_stopword_1 = remove_stopword(tagged_1, stop_tag_list, Kor_stopwords)\n",
    "wo_stopword_2 = remove_stopword(tagged_2, stop_tag_list, Kor_stopwords)\n",
    "wo_stopword_3 = remove_stopword(tagged_3, stop_tag_list, Kor_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-4. Tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_1 = tokenizing(wo_stopword_1, tagList, 'all')\n",
    "all_2 = tokenizing(wo_stopword_2, tagList, 'all')\n",
    "all_3 = tokenizing(wo_stopword_3, tagList, 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_1 = tokenizing(wo_stopword_1, tagList, 'noun')\n",
    "noun_2 = tokenizing(wo_stopword_2, tagList, 'noun')\n",
    "noun_3 = tokenizing(wo_stopword_3, tagList, 'noun')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_1 = tokenizing(wo_stopword_1, tagList, 'verb')\n",
    "verb_2 = tokenizing(wo_stopword_2, tagList, 'verb')\n",
    "verb_3 = tokenizing(wo_stopword_3, tagList, 'verb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjective_1 = tokenizing(wo_stopword_1, tagList, 'adjective')\n",
    "adjective_2 = tokenizing(wo_stopword_2, tagList, 'adjective')\n",
    "adjective_3 = tokenizing(wo_stopword_3, tagList, 'adjective')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "adverb_1 = tokenizing(wo_stopword_1, tagList, 'adverb')\n",
    "adverb_2 = tokenizing(wo_stopword_2, tagList, 'adverb')\n",
    "adverb_3 = tokenizing(wo_stopword_3, tagList, 'adverb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save PreProcessed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pickle(all_1, file_name='all', root=RESULT_1)\n",
    "to_pickle(all_2, file_name='all', root=RESULT_2)\n",
    "to_pickle(all_3, file_name='all', root=RESULT_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pickle(noun_1, file_name='noun', root=RESULT_1)\n",
    "to_pickle(noun_2, file_name='noun', root=RESULT_2)\n",
    "to_pickle(noun_3, file_name='noun', root=RESULT_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pickle(verb_1, file_name='verb', root=RESULT_1)\n",
    "to_pickle(verb_2, file_name='verb', root=RESULT_2)\n",
    "to_pickle(verb_3, file_name='verb', root=RESULT_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pickle(adjective_1, file_name='adjective', root=RESULT_1)\n",
    "to_pickle(adjective_2, file_name='adjective', root=RESULT_2)\n",
    "to_pickle(adjective_3, file_name='adjective', root=RESULT_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pickle(adverb_1, file_name='adverb', root=RESULT_1)\n",
    "to_pickle(adverb_2, file_name='adverb', root=RESULT_2)\n",
    "to_pickle(adverb_3, file_name='adverb', root=RESULT_3)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "33a3111211be4281f3a8c4a9b25563b8d253df502c7e31f5318895c1792a97cb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('py38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
