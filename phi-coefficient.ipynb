{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self defined Modules\n",
    "from myModules.utils import merge\n",
    "from myModules.plot.plotNetwork import vocaDict, Network\n",
    "\n",
    "# General Modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pickle\n",
    "from itertools import product\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# visualize\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLP\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = './processed-data/'\n",
    "\n",
    "PERIOD_1 = DATA_ROOT + 'period-1/'\n",
    "PERIOD_2 = DATA_ROOT + 'period-2/'\n",
    "PERIOD_3 = DATA_ROOT + 'period-3/'\n",
    "\n",
    "RESULT_ROOT = './Result/3구간/'\n",
    "\n",
    "RESULT_1 = RESULT_ROOT + '/1시기/ST/'\n",
    "RESULT_2 = RESULT_ROOT + '/2시기/ST/'\n",
    "RESULT_3 = RESULT_ROOT + '/3시기/ST/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PERIOD_1+\"lemmatized-all.pkl\", \"rb\") as f:\n",
    "    all_1 = pickle.load(f)\n",
    "with open(PERIOD_1+\"lemmatized-noun.pkl\", \"rb\") as f:\n",
    "    noun_1 = pickle.load(f)\n",
    "with open(PERIOD_1+\"lemmatized-verb.pkl\", \"rb\") as f:\n",
    "    verb_1 = pickle.load(f)\n",
    "with open(PERIOD_1+\"lemmatized-adjective.pkl\", \"rb\") as f:\n",
    "    adjective_1 = pickle.load(f)\n",
    "with open(PERIOD_1+\"lemmatized-adverb.pkl\", \"rb\") as f:\n",
    "    adverb_1 = pickle.load(f)\n",
    "\n",
    "\n",
    "with open(PERIOD_2+\"lemmatized-all.pkl\", \"rb\") as f:\n",
    "    all_2 = pickle.load(f)\n",
    "with open(PERIOD_2+\"lemmatized-noun.pkl\", \"rb\") as f:\n",
    "    noun_2 = pickle.load(f)\n",
    "with open(PERIOD_2+\"lemmatized-verb.pkl\", \"rb\") as f:\n",
    "    verb_2 = pickle.load(f)\n",
    "with open(PERIOD_2+\"lemmatized-adjective.pkl\", \"rb\") as f:\n",
    "    adjective_2 = pickle.load(f)\n",
    "with open(PERIOD_2+\"lemmatized-adverb.pkl\", \"rb\") as f:\n",
    "    adverb_2 = pickle.load(f)\n",
    "\n",
    "with open(PERIOD_3+\"lemmatized-all.pkl\", \"rb\") as f:\n",
    "    all_3 = pickle.load(f)\n",
    "with open(PERIOD_3+\"lemmatized-noun.pkl\", \"rb\") as f:\n",
    "    noun_3 = pickle.load(f)\n",
    "with open(PERIOD_3+\"lemmatized-verb.pkl\", \"rb\") as f:\n",
    "    verb_3 = pickle.load(f)\n",
    "with open(PERIOD_3+\"lemmatized-adjective.pkl\", \"rb\") as f:\n",
    "    adjective_3 = pickle.load(f)\n",
    "with open(PERIOD_3+\"lemmatized-adverb.pkl\", \"rb\") as f:\n",
    "    adverb_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phi Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_into_one_string(data):\n",
    "    result = []\n",
    "\n",
    "    for article in data:\n",
    "        result.append(' '.join(article))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = tokens_into_one_string(all_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer().fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = tfidf_vectorizer.transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list = list(range(len(corr_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9272d6f4a89478c8da0b4acfa1d065f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6707 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edges = []\n",
    "corr_thresh = 0.8\n",
    "length = len(corr_df)\n",
    "\n",
    "for row in tqdm(range(length)):\n",
    "    for col in range(row + 1, length):\n",
    "        if (corr_df.loc[row, col] >= corr_thresh):\n",
    "            edges.append([row, col, corr_df.loc[row, col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_df = pd.DataFrame(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_df.columns = ['word1', 'word2', 'corr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_edge_df = edge_df.sort_values(by='corr').reset_index().drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1440563</th>\n",
       "      <td>3551</td>\n",
       "      <td>5618</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440564</th>\n",
       "      <td>3963</td>\n",
       "      <td>6137</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440565</th>\n",
       "      <td>3963</td>\n",
       "      <td>6122</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440566</th>\n",
       "      <td>4312</td>\n",
       "      <td>5183</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440567</th>\n",
       "      <td>1294</td>\n",
       "      <td>6138</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445558</th>\n",
       "      <td>1378</td>\n",
       "      <td>1912</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445559</th>\n",
       "      <td>1378</td>\n",
       "      <td>1913</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445560</th>\n",
       "      <td>1378</td>\n",
       "      <td>1930</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445561</th>\n",
       "      <td>1378</td>\n",
       "      <td>1932</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445562</th>\n",
       "      <td>1378</td>\n",
       "      <td>1860</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word1  word2  corr\n",
       "1440563   3551   5618   1.0\n",
       "1440564   3963   6137   1.0\n",
       "1440565   3963   6122   1.0\n",
       "1440566   4312   5183   1.0\n",
       "1440567   1294   6138   1.0\n",
       "...        ...    ...   ...\n",
       "1445558   1378   1912   1.0\n",
       "1445559   1378   1913   1.0\n",
       "1445560   1378   1930   1.0\n",
       "1445561   1378   1932   1.0\n",
       "1445562   1378   1860   1.0\n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_edge_df[-5001:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "voca_dict = tfidf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_from_id(id, voca_dict):\n",
    "    for key, val in voca_dict.items():\n",
    "        if val == id:\n",
    "            return key\n",
    "\n",
    "def edge_df_with_token(edge_df, voca_dict):\n",
    "    result = []\n",
    "\n",
    "    for idx in tqdm(range(len(edge_df))):\n",
    "        result.append([get_token_from_id(edge_df.loc[idx, 'word1'], voca_dict), get_token_from_id(edge_df.loc[idx, 'word2'], voca_dict), edge_df.loc[idx, 'corr']])\n",
    "        print(result)\n",
    "    \n",
    "    result = pd.DataFrame(result)\n",
    "    result.columns = ['word1', 'word2', 'corr']\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'copper'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_token_from_id(1294, voca_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transcontinental'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_token_from_id(6138, voca_dict)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "33a3111211be4281f3a8c4a9b25563b8d253df502c7e31f5318895c1792a97cb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('py38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
