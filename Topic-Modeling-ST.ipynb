{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English Data Topic Modeling Using `LDA`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeul Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self defined Modules\n",
    "from myModules.utils.merge.mergeOverPeriod import merge\n",
    "from myModules.TopicModeling.LDA.ldaModeling import buildDTM, topicWords, visualizeLDA\n",
    "\n",
    "# General Modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from itertools import product\n",
    "\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# NLP\n",
    "from gensim import models\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = './processed-data/'\n",
    "\n",
    "PERIOD_1 = DATA_ROOT + 'period-1/'\n",
    "PERIOD_2 = DATA_ROOT + 'period-2/'\n",
    "PERIOD_3 = DATA_ROOT + 'period-3/'\n",
    "\n",
    "RESULT_ROOT = './Result/3구간/'\n",
    "\n",
    "RESULT_1 = RESULT_ROOT + '/1시기/ST/'\n",
    "RESULT_2 = RESULT_ROOT + '/2시기/ST/'\n",
    "RESULT_3 = RESULT_ROOT + '/3시기/ST/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PERIOD_1+\"lemmatized-all.pkl\", \"rb\") as f:\n",
    "    all_1 = pickle.load(f)\n",
    "with open(PERIOD_1+\"lemmatized-noun.pkl\", \"rb\") as f:\n",
    "    noun_1 = pickle.load(f)\n",
    "with open(PERIOD_1+\"lemmatized-verb.pkl\", \"rb\") as f:\n",
    "    verb_1 = pickle.load(f)\n",
    "with open(PERIOD_1+\"lemmatized-adjective.pkl\", \"rb\") as f:\n",
    "    adjective_1 = pickle.load(f)\n",
    "with open(PERIOD_1+\"lemmatized-adverb.pkl\", \"rb\") as f:\n",
    "    adverb_1 = pickle.load(f)\n",
    "\n",
    "\n",
    "with open(PERIOD_2+\"lemmatized-all.pkl\", \"rb\") as f:\n",
    "    all_2 = pickle.load(f)\n",
    "with open(PERIOD_2+\"lemmatized-noun.pkl\", \"rb\") as f:\n",
    "    noun_2 = pickle.load(f)\n",
    "with open(PERIOD_2+\"lemmatized-verb.pkl\", \"rb\") as f:\n",
    "    verb_2 = pickle.load(f)\n",
    "with open(PERIOD_2+\"lemmatized-adjective.pkl\", \"rb\") as f:\n",
    "    adjective_2 = pickle.load(f)\n",
    "with open(PERIOD_2+\"lemmatized-adverb.pkl\", \"rb\") as f:\n",
    "    adverb_2 = pickle.load(f)\n",
    "\n",
    "with open(PERIOD_3+\"lemmatized-all.pkl\", \"rb\") as f:\n",
    "    all_3 = pickle.load(f)\n",
    "with open(PERIOD_3+\"lemmatized-noun.pkl\", \"rb\") as f:\n",
    "    noun_3 = pickle.load(f)\n",
    "with open(PERIOD_3+\"lemmatized-verb.pkl\", \"rb\") as f:\n",
    "    verb_3 = pickle.load(f)\n",
    "with open(PERIOD_3+\"lemmatized-adjective.pkl\", \"rb\") as f:\n",
    "    adjective_3 = pickle.load(f)\n",
    "with open(PERIOD_3+\"lemmatized-adverb.pkl\", \"rb\") as f:\n",
    "    adverb_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling\n",
    "\n",
    "- topic num : 가설로 설정한 topic의 갯수\n",
    "    1. Topic Coherence\n",
    "        - 주제의 일관성 측정\n",
    "        - 모델링이 잘 될수록 한 주제 안에는 의미론적으로 유사한 단어가 많이 모여있게 됨.\n",
    "        - 높을수록 의미론적 일관성이 높다.\n",
    "        - Coherence가 높아지면 Monotonic 해지는 문제점이 생긴다.\n",
    "        - coherence가 너무 높아지면 정보의 양이 줄어들고, coherence가 너무 낮으면 정보들의 연관성이 없어져 분석의 의미가 없다.\n",
    "    2. Perplexity   \n",
    "        - Coherence가 이 data에서 topic number가 늘어날수록 거의 같이 늘어나는 경향을 보임\n",
    "        - 따라서 다른 평가기준도 함께 고려해야겠다는 생각에 추가\n",
    "        - 작아질수록 토픽모델이 문서를 잘 반영한다.\n",
    "\n",
    "- lda modeling 결과를 시각화해 보았을 때, 10이상으로 넘어가면 할당되지 않는 빈 id들이 발견되었습니다.\n",
    "    - 따라서 시험할 k값의 범위를 1~15까지 자연수로 설정하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPIC_WORDS = 30\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BestLDAPram:\n",
    "    def __init__(self, data, random_state=42):\n",
    "        self.data = data\n",
    "        self.random_state = random_state\n",
    "        self.corpus, self.dictionary = buildDTM(self.data)\n",
    "    \n",
    "    def grid_search(self, param_grid, result_save_root='./'):\n",
    "        grid_search_table = []\n",
    "\n",
    "        iterator = list(product(param_grid['num_topics'], param_grid['alpha'], param_grid['eta']))\n",
    "\n",
    "        for num_topic, alpha, eta in tqdm(iterator, desc=\"LDA Parameter Grid Searching\"):\n",
    "            coherence_value = self.calc_coherence(num_topic=num_topic, alpha=alpha, eta=eta)\n",
    "            grid_search_table.append([num_topic, alpha, eta, coherence_value])\n",
    "        \n",
    "        self.grid_search_table = pd.DataFrame(grid_search_table)\n",
    "        self.grid_search_table.columns = ['Topics', 'Alpha', 'Eta', 'Coherence']\n",
    "\n",
    "        self.grid_search_table.to_csv(result_save_root+'lda-param-grid-search.csv', index=False)\n",
    "    \n",
    "    def calc_coherence(self, num_topic, alpha, eta):\n",
    "        model = models.LdaMulticore(corpus=self.corpus, id2word=self.dictionary, num_topics=num_topic, \\\n",
    "            alpha=alpha, eta=eta, random_state=self.random_state)\n",
    "        \n",
    "        coherence_model = CoherenceModel(model=model, texts=self.data, dictionary=self.dictionary, coherence='c_v')\n",
    "        \n",
    "        return coherence_model.get_coherence()\n",
    "    \n",
    "    def load_grid_search_result(self, grid_search_result):\n",
    "        self.grid_search_table = grid_search_result\n",
    "    \n",
    "    def get_best_params(self):\n",
    "        num_topics = self.grid_search_table.Topics.unique()\n",
    "        coherences = []\n",
    "        for ntopic in num_topics:\n",
    "            coherences.append(self.grid_search_table.Coherence[self.grid_search_table.Topics == ntopic].mean())\n",
    "        \n",
    "        idx = np.argmax(coherences)\n",
    "        best_num_topics = num_topics[idx]\n",
    "\n",
    "        alphas = self.grid_search_table.Alpha.unique()\n",
    "        coherences = []\n",
    "        for alpha in alphas:\n",
    "            coherences.append(self.grid_search_table.Coherence[self.grid_search_table.Alpha == alpha].mean())\n",
    "        \n",
    "        idx = np.argmax(coherences)\n",
    "        best_alpha = alphas[idx]\n",
    "        \n",
    "        etas = self.grid_search_table.Eta.unique()\n",
    "        coherences = []\n",
    "        for eta in etas:\n",
    "            coherences.append(self.grid_search_table.Coherence[self.grid_search_table.Eta == eta].mean())\n",
    "        \n",
    "        idx = np.argmax(coherences)\n",
    "        best_eta = etas[idx]\n",
    "\n",
    "        return best_num_topics, best_alpha, best_eta\n",
    "    \n",
    "    def plot_coherence_per_topics(self, title='Coherence per Topic Num', root='./'):\n",
    "        plt.figure()\n",
    "\n",
    "        num_topics = self.grid_search_table.Topics.unique()\n",
    "        coherences = []\n",
    "        for ntopic in num_topics:\n",
    "            coherences.append(self.grid_search_table.Coherence[self.grid_search_table.Topics == ntopic].mean())\n",
    "\n",
    "        plt.plot(num_topics, coherences)\n",
    "\n",
    "        plt.xlabel('Number of Topics')\n",
    "        plt.ylabel('Coherence')\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.savefig(root+title+'.png')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_coherence_per_alpha(self, title='Coherence per alpha', root='./'):\n",
    "        plt.figure()\n",
    "\n",
    "        alphas = self.grid_search_table.Alpha.unique()\n",
    "        coherences = []\n",
    "        for alpha in alphas:\n",
    "            coherences.append(self.grid_search_table.Coherence[self.grid_search_table.Alpha == alpha].mean())\n",
    "\n",
    "        plt.plot(alphas, coherences)\n",
    "\n",
    "        plt.xlabel('Alpha')\n",
    "        plt.ylabel('Coherence')\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.savefig(root+title+'.png')\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_coherence_per_eta(self, title='Coherence per eta', root='./'):\n",
    "        plt.figure()\n",
    "\n",
    "        etas = self.grid_search_table.Eta.unique()\n",
    "        coherences = []\n",
    "        for eta in etas:\n",
    "            coherences.append(self.grid_search_table.Coherence[self.grid_search_table.Eta == eta].mean())\n",
    "\n",
    "        plt.plot(etas, coherences)\n",
    "\n",
    "        plt.xlabel('Eta')\n",
    "        plt.ylabel('Coherence')\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.savefig(root+title+'.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Period 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_param = BestLDAPram(data=all_1, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prameter의 실험 범위를 설정하고 모든 조합에 대해 Coherence를 계산하여 parameter tuning\n",
    "\n",
    "- 최초 1회만 실행 -> 약 3시간 정도 걸림.\n",
    "- grid search 결과를 csv 파일로 저장 -> 불러와서 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = range(2, 11)\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "alpha.extend(['symmetric', 'asymmetric'])\n",
    "eta = list(np.arange(0.01, 1, 0.3))\n",
    "eta.append('symmetric')\n",
    "\n",
    "param_grid = {\n",
    "    'num_topics' : num_topics,\n",
    "    'alpha' : alpha,\n",
    "    'eta' : eta\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_param.grid_search(param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_table = pd.read_csv('./lda-param-grid-search.csv')\n",
    "\n",
    "lda_param.load_grid_search_result(grid_search_result=grid_search_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS, ALPHA, ETA = lda_param.get_best_params()\n",
    "\n",
    "print(f\"best Number of Topics : {NUM_TOPICS}\\nbest Alpha : {ALPHA}\\nbest Eta : {ETA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_param.plot_coherence_per_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_param.plot_coherence_per_alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_param.plot_coherence_per_eta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corp, Dict = buildDTM(all_1)\n",
    "model = models.ldamodel.LdaModel(corpus=Corp, id2word=Dict, num_topics=NUM_TOPICS, \\\n",
    "            passes=PASSES, alpha=ALPHA, eta=ETA, random_state=random_state)\n",
    "topicdf = topicWords(model, NUM_TOPIC_WORDS)\n",
    "topicdf.to_csv(RESULT_1+'[Period 1] topic words.csv', index=False)\n",
    "data = visualizeLDA(model, Corp, Dict)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Period 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_param = BestLDAPram(data=all_2, passes=PASSES, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prameter의 실험 범위를 설정하고 모든 조합에 대해 Coherence를 계산하여 parameter tuning\n",
    "\n",
    "- 최초 1회만 실행 -> 약 3시간 정도 걸림.\n",
    "- grid search 결과를 csv 파일로 저장 -> 불러와서 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'num_topics' : range(2, 11),\n",
    "    'alpha' : [i * 0.001 for i in range(1, 11)],\n",
    "    'eta' : [i * 0.01 for i in range(1, 11)]\n",
    "}\n",
    "\n",
    "lda_param.grid_search(param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS, ALPHA, ETA = lda_param.get_best_params()\n",
    "\n",
    "print(f\"best Number of Topics : {NUM_TOPICS}\\nbest Alpha : {ALPHA}\\nbest Eta : {ETA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_param.plot_coherence_per_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_param.plot_coherence_per_alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_param.plot_coherence_per_eta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corp, Dict = buildDTM(all_2)\n",
    "model = models.ldamodel.LdaModel(corpus=Corp, id2word=Dict, num_topics=NUM_TOPICS, \\\n",
    "            passes=PASSES, alpha=ALPHA, eta=ETA, random_state=random_state)\n",
    "topicdf = topicWords(model, NUM_TOPIC_WORDS)\n",
    "topicdf.to_csv(RESULT_2+'[Period 2] topic words.csv', index=False)\n",
    "data = visualizeLDA(model, Corp, Dict)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Period 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_param = BestLDAPram(data=all_3, passes=PASSES, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prameter의 실험 범위를 설정하고 모든 조합에 대해 Coherence를 계산하여 parameter tuning\n",
    "\n",
    "- 최초 1회만 실행 -> 약 3시간 정도 걸림.\n",
    "- grid search 결과를 csv 파일로 저장 -> 불러와서 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'num_topics' : range(2, 11),\n",
    "    'alpha' : [i * 0.001 for i in range(1, 11)],\n",
    "    'eta' : [i * 0.01 for i in range(1, 11)]\n",
    "}\n",
    "\n",
    "lda_param.grid_search(param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS, ALPHA, ETA = lda_param.get_best_params()\n",
    "\n",
    "print(f\"best Number of Topics : {NUM_TOPICS}\\nbest Alpha : {ALPHA}\\nbest Eta : {ETA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_param.plot_coherence_per_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_param.plot_coherence_per_alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_param.plot_coherence_per_eta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corp, Dict = buildDTM(all_3)\n",
    "model = models.ldamodel.LdaModel(corpus=Corp, id2word=Dict, num_topics=NUM_TOPICS, \\\n",
    "            passes=PASSES, alpha=ALPHA, eta=ETA, random_state=random_state)\n",
    "topicdf = topicWords(model, NUM_TOPIC_WORDS)\n",
    "topicdf.to_csv(RESULT_3+'[Period 3] topic words.csv', index=False)\n",
    "data = visualizeLDA(model, Corp, Dict)\n",
    "\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "33a3111211be4281f3a8c4a9b25563b8d253df502c7e31f5318895c1792a97cb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('py38': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
